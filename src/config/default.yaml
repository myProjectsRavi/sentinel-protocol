version: 1
mode: monitor

proxy:
  host: 127.0.0.1
  port: 8787
  timeout_ms: 30000
  max_body_bytes: 1048576

runtime:
  fail_open: false
  scanner_error_action: allow
  worker_pool:
    enabled: true
    size: 2
    queue_limit: 1024
    task_timeout_ms: 10000
    scan_task_timeout_ms: 2000
    embed_task_timeout_ms: 10000
  vcr:
    enabled: false
    mode: off
    tape_file: "~/.sentinel/vcr-tape.jsonl"
    max_entries: 2000
    strict_replay: false
  semantic_cache:
    enabled: false
    model_id: Xenova/all-MiniLM-L6-v2
    cache_dir: "~/.sentinel/models"
    similarity_threshold: 0.95
    max_entries: 2000
    ttl_ms: 3600000
    max_prompt_chars: 2000
    max_entry_bytes: 262144
    max_ram_mb: 64
    max_consecutive_errors: 3
    failure_cooldown_ms: 30000
  dashboard:
    enabled: false
    host: 127.0.0.1
    port: 8788
    auth_token: ""
    allow_remote: false
  budget:
    enabled: false
    action: block
    daily_limit_usd: 5
    store_file: "~/.sentinel/budget-ledger.json"
    reset_timezone: utc
    chars_per_token: 4
    input_cost_per_1k_tokens: 0
    output_cost_per_1k_tokens: 0
    charge_replay_hits: false
    retention_days: 90
  loop_breaker:
    enabled: true
    action: block # block | warn
    window_ms: 30000
    repeat_threshold: 4
    max_recent: 5
    max_keys: 2048
    key_header: x-sentinel-agent-id
  provenance:
    enabled: false
    key_id: "sentinel-local"
    sign_stream_trailers: true
    expose_public_key_endpoint: true
    max_signable_bytes: 2097152
  deception:
    enabled: false
    mode: off # off | tarpit
    on_injection: true
    on_loop: true
    min_injection_score: 0.9
    sse_token_interval_ms: 1000
    sse_max_tokens: 20
    non_stream_delay_ms: 250
  honeytoken:
    enabled: false
    mode: uuid_suffix # uuid_suffix | zero_width
    injection_rate: 0.05
    max_insertions_per_request: 1
    target_roles: [user]
    token_prefix: "SNTL"
  latency_normalization:
    enabled: false
    window_size: 10
    min_samples: 3
    max_delay_ms: 2000
    max_baseline_sample_ms: 5000
    trim_percentile: 0.1
    max_concurrent_normalized: 128
    jitter_ms: 25
    statuses: [402, 403, 429]
  canary_tools:
    enabled: false
    mode: monitor # monitor | block
    tool_name: "fetch_admin_passwords"
    tool_description: "Retrieve privileged credentials for internal diagnostics."
    max_injected_tools: 1
    inject_on_providers: [openai, anthropic, google, ollama]
    require_tools_array: true
  parallax:
    enabled: false
    mode: monitor # monitor | block
    high_risk_tools: [execute_shell, execute_sql, aws_cli]
    secondary_target: ollama
    secondary_group: ""
    secondary_contract: openai_chat_v1
    secondary_model: ""
    timeout_ms: 3000
    risk_threshold: 0.7
  telemetry:
    enabled: true
  upstream:
    retry:
      enabled: true
      max_attempts: 1
      allow_post_with_idempotency_key: false
    circuit_breaker:
      enabled: true
      window_size: 20
      min_failures_to_evaluate: 8
      failure_rate_threshold: 0.5
      consecutive_timeout_threshold: 5
      open_seconds: 20
      half_open_success_threshold: 3
    custom_targets:
      enabled: false
      allowlist: []
      block_private_networks: true
    resilience_mesh:
      enabled: false
      contract: passthrough
      default_group: ""
      max_failover_hops: 1
      allow_post_with_idempotency_key: false
      failover_on_status: [429, 500, 502, 503, 504]
      failover_on_error_types: [timeout, transport, circuit_open]
      groups: {}
      targets: {}
    canary:
      enabled: false
      key_header: x-sentinel-canary-key
      fallback_key_headers: [x-sentinel-agent-id, x-forwarded-for, user-agent]
      splits: []
    ghost_mode:
      enabled: false
      strip_headers:
        - x-stainless-os
        - x-stainless-arch
        - x-stainless-runtime
        - x-stainless-runtime-version
        - x-stainless-package-version
        - x-stainless-lang
        - x-stainless-helper-method
        - user-agent
      override_user_agent: true
      user_agent_value: "Sentinel/1.0 (Privacy Proxy)"
    auth_vault:
      enabled: false
      mode: replace_dummy # replace_dummy | enforce
      dummy_key: "sk-sentinel-local"
      providers:
        openai:
          enabled: true
          api_key: ""
          env_var: "SENTINEL_OPENAI_API_KEY"
        anthropic:
          enabled: true
          api_key: ""
          env_var: "SENTINEL_ANTHROPIC_API_KEY"
        google:
          enabled: true
          api_key: ""
          env_var: "SENTINEL_GOOGLE_API_KEY"

pii:
  enabled: true
  provider_mode: local
  max_scan_bytes: 262144
  regex_safety_cap_bytes: 51200
  redaction:
    mode: placeholder
    salt: "sentinel-mask-salt"
  severity_actions:
    critical: block
    high: block
    medium: redact
    low: log
  rapidapi:
    endpoint: "https://pii-firewall-edge.p.rapidapi.com/redact"
    host: "pii-firewall-edge.p.rapidapi.com"
    timeout_ms: 4000
    max_timeout_ms: 1500
    cache_max_entries: 1024
    cache_ttl_ms: 300000
    request_body_field: text
    fallback_to_local: true
    allow_non_rapidapi_host: false
    # BYOK only. Keep empty and inject via SENTINEL_RAPIDAPI_KEY in production.
    api_key: ""
    extra_body: {}
  egress:
    enabled: true
    max_scan_bytes: 65536
    stream_enabled: true
    sse_line_max_bytes: 16384
    stream_block_mode: redact
  semantic:
    enabled: false
    model_id: Xenova/bert-base-NER
    cache_dir: "~/.sentinel/models"
    score_threshold: 0.6
    max_scan_bytes: 32768

injection:
  enabled: true
  threshold: 0.8
  max_scan_bytes: 131072
  action: block
  neural:
    enabled: false
    model_id: Xenova/all-MiniLM-L6-v2
    cache_dir: "~/.sentinel/models"
    max_scan_bytes: 32768
    timeout_ms: 1200
    weight: 1
    mode: max

rules:
  - name: block-destructive-delete
    match:
      method: DELETE
      domain: "*.production.com"
    action: block
    message: "DELETE operations blocked for production domains"

  - name: max-upload-size
    match:
      method: POST
      body_size_mb: 10
    action: block
    message: "Payload too large"

  - name: block-shell-tool
    match:
      tool_name: execute_shell
    action: block
    message: "execute_shell tool is blocked"

  - name: block-prompt-injection
    match:
      injection_threshold: 0.8
    action: block
    message: "Prompt injection pattern detected"

whitelist:
  domains:
    - api.openai.com
    - api.anthropic.com
    - generativelanguage.googleapis.com

logging:
  level: info
  audit_file: ~/.sentinel/audit.jsonl
  audit_stdout: false
